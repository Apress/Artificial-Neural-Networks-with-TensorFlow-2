{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder-Custom.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvmkUw-ruFA4"
      },
      "source": [
        "# AutoEncoders - custom built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0gDGF0CKHPM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "import skimage\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.util import crop, pad\n",
        "from skimage.morphology import label\n",
        "from skimage.color import rgb2gray, gray2rgb, rgb2lab, lab2rgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model,Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Dense, UpSampling2D, RepeatVector, Reshape\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgQc7VfNvGXB"
      },
      "source": [
        "## Using Kaggle dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhrM6T34vcBy"
      },
      "source": [
        "## Installing Kaggle Library \n",
        "\n",
        "Installing the Kaggle library and authenticatng it with your kaggle account to download the dataset\n",
        "\n",
        "Link : https://www.kaggle.com/thedownhill/art-images-drawings-painting-sculpture-engraving\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlP-DhLKkOZr"
      },
      "source": [
        "#!pip install -q kaggle\n",
        "#!mkdir ~/.kaggle\n",
        "#!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "#api_token = {\"username\":\"Your UserName\",\"key\":\"Your key\"}\n",
        "\n",
        "#import json\n",
        "\n",
        "#with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "#    json.dump(api_token, file)\n",
        "\n",
        "#!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download -d thedownhill/art-images-drawings-painting-sculpture-engraving"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkT70pXMoa8s"
      },
      "source": [
        "# Optionally, you may download data from book site"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhXEJlsJhQke"
      },
      "source": [
        "!wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1CKs7s_MZMuZFBXDchcL_AgmCxgPBTJXK' -O art-images-drawings-painting-sculpture-engraving.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2kLfXBWwCuV"
      },
      "source": [
        "## Unzipping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP9AKnEtkVAV"
      },
      "source": [
        "!unzip art-images-drawings-painting-sculpture-engraving.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuFWKnTGw94w"
      },
      "source": [
        "# Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC8BC31WI4QS"
      },
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "TRAIN_PATH = '/content/dataset/dataset_updated/training_set/painting/'\n",
        "train_ids = next(os.walk(TRAIN_PATH))[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrzRma8dyNAE"
      },
      "source": [
        "# Counting corrupt images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hLFBf9GzWvX"
      },
      "source": [
        "missing_count = 0\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + id_+''\n",
        "    try:\n",
        "        img = imread(path)\n",
        "    except:\n",
        "        missing_count += 1\n",
        "\n",
        "print(\"\\n\\nTotal missing: \"+ str(missing_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np5f6ZUVzmbZ"
      },
      "source": [
        "# Creating training set\n",
        "Remove all bad images from the set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNmdNuR_zXyJ"
      },
      "source": [
        "X_train = np.zeros((len(train_ids)-missing_count, IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
        "missing_images = 0\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + id_+''\n",
        "    try:\n",
        "        img = imread(path)\n",
        "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "        X_train[n-missing_images] = img\n",
        "    except:\n",
        "        missing_images += 1\n",
        "\n",
        "X_train = X_train.astype('float32') / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdy_pU-3yeRt"
      },
      "source": [
        "# Displaying sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xk_bA7SJ7JF"
      },
      "source": [
        "plt.imshow(X_train[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6iRSyQdyyT9"
      },
      "source": [
        "# Creating Training/Testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l92DO2lEKO8L"
      },
      "source": [
        "x_train, x_test = train_test_split(X_train, test_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amyyF_v5Tdoj"
      },
      "source": [
        "# Preprocessing Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TG5ObTh0swe"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juxt5Fu6Ld0n"
      },
      "source": [
        "def create_training_batches(dataset=X_train, batch_size = 20):\n",
        "    # iteration for every image\n",
        "    for batch in datagen.flow(dataset, batch_size=batch_size): \n",
        "        # convert from rgb to grayscale\n",
        "        X_batch = rgb2gray(batch)                              \n",
        "        # convert rgb to Lab format\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        # extract L component\n",
        "        X_batch = lab_batch[:,:,:,0] \n",
        "        # reshape \n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,)) \n",
        "        # extract a and b features of the image\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield X_batch, Y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKmRUUjZMOs5"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93RQHbbe-siC"
      },
      "source": [
        "# the input for the encoder layer\n",
        "inputs1 = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1,)) \n",
        "\n",
        "# encoder\n",
        "\n",
        "# Using Conv2d to reduce the size of feature maps and image size\n",
        "# convert image to 128x128\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(inputs1) \n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)  \n",
        "# convert image to 64x64\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "# convert image to 32x32\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "# mid-level feature extractions\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "# decoder\n",
        "\n",
        "# Adding colors to the grayscale image and upsizing it\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output) # image size 64x64\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output) # image size 128x128\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output) # image size 256x256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whCdk5HmKE7X"
      },
      "source": [
        "# compiling  model\n",
        "model = Model(inputs=inputs1, outputs=decoder_output)\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qAa0CBrzGkx"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J_w-58fMyOi"
      },
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3JAM4V1Nnq"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e58k6bSMNxD3"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "model.fit_generator(create_training_batches(X_train,BATCH_SIZE),\n",
        "            epochs= 100,\n",
        "            verbose=1,\n",
        "            steps_per_epoch=X_train.shape[0]/BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQUaNKG21UWI"
      },
      "source": [
        "# Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rM03RlqN9l9"
      },
      "source": [
        "test_image = rgb2lab(x_test)[:,:,:,0] \n",
        "test_image = test_image.reshape(test_image.shape+(1,)) \n",
        "output = model.predict(test_image) \n",
        "output = output * 128 \n",
        "\n",
        "# making the output image array\n",
        "generated_images = np.zeros((len(output),256, 256, 3)) \n",
        "\n",
        "for i in range(len(output)): #iterating for the output\n",
        "    cur = np.zeros((256, 256, 3)) # dummy array\n",
        "    cur[:,:,0] = test_image[i][:,:,0] #assigning the gray scale component\n",
        "    cur[:,:,1:] = output[i] #assigning the a and b component\n",
        "    #converting from lab to rgb format as plt only work for rgb mode\n",
        "    generated_images[i] = lab2rgb(cur) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVVjIrpM1jlc"
      },
      "source": [
        "# Display images - grayscale, generated and original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_-IVc47zZpM"
      },
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(10):\n",
        "    # grayscale\n",
        "    plt.subplot(3, 10, i + 1)\n",
        "    plt.imshow(rgb2gray(x_test)[i].reshape(256, 256))\n",
        "    plt.gray()\n",
        "    plt.axis('off')\n",
        " \n",
        "    # recolorization\n",
        "    plt.subplot(3, 10, i + 1 +10)\n",
        "    plt.imshow(generated_images[i].reshape(256, 256,3))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # original\n",
        "    plt.subplot(3, 10, i + 1 + 20)\n",
        "    plt.imshow(x_test[i].reshape(256, 256,3))\n",
        "    plt.axis('off')\n",
        " \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kaiL48-Otuy"
      },
      "source": [
        "# Testing on an unseen image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW_gnSECoqSp"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Apress/artificial-neural-networks-with-tensorflow-2/main/ch14/mountain.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DMD6_9O4j6g"
      },
      "source": [
        "img = imread(\"mountain.jpg\")\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adoZA1SBvE4B"
      },
      "source": [
        "img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "img = img.astype('float32') / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRT87DaS4q4_"
      },
      "source": [
        "test_image = rgb2lab(img)[:,:,0] \n",
        "test_image = test_image.reshape((1,)+test_image.shape+(1,))\n",
        "output = model.predict(test_image) \n",
        "output = output * 128 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5n65HC403x"
      },
      "source": [
        "plt.imshow(output)\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}