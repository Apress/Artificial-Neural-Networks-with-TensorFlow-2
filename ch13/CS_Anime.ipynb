{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS-Anime.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lIM4sYhKjb9"
      },
      "source": [
        "# Anime image generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KpvP9UApCUx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import UpSampling2D, Conv2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXuI8R7Mz8NY"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdCSidjmbQAh"
      },
      "source": [
        "! wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1z7rXRIFtRBFZHt-Mmti4HxrxHqUfG3Y8' -O tf-book.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWrk1HAAcO8U"
      },
      "source": [
        "!unzip tf-book.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKz_MDs90Dmw"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH6a-ibQbgqm"
      },
      "source": [
        "def load_dataset(batch_size, img_shape, data_dir=None):\n",
        "    # Create a tuple of size(30000,64,64,3)\n",
        "    sample_dim = (batch_size,) + img_shape   \n",
        "    # Create an uninitialized array of shape (30000,64,64,3)  \n",
        "    sample = np.empty(sample_dim, dtype=np.float32) \n",
        "    # Extract all images from our file\n",
        "    all_data_dirlist = list(glob.glob(data_dir)) \n",
        "    \n",
        "    # Randomly select an image file from our data list\n",
        "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size) \n",
        "  \n",
        "    for index,img_filename in enumerate(sample_imgs_paths):\n",
        "        # Open the image\n",
        "        image = Image.open(img_filename) \n",
        "        # Resize the image\n",
        "        image = image.resize(img_shape[:-1]) \n",
        "        # Convert the input into an array\n",
        "        image = np.asarray(image) \n",
        "        # Normalize data\n",
        "        image = (image/127.5) -1 \n",
        "        # Assign the preprocessed image to our sample\n",
        "        sample[index,...] = image  \n",
        "    print('data loaded')\n",
        "    return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2-Z1EMoiZHg"
      },
      "source": [
        "x_train=load_dataset(30000,(64,64,3), \"/content/tf-book/chapter13/anime/data/*.png\")\n",
        "BUFFER_SIZE = 30000\n",
        "BATCH_SIZE = 256\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET-6GJix0J8E"
      },
      "source": [
        "# Displaying data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNxwfPAE-O5g"
      },
      "source": [
        "n = 10\n",
        "f = plt.figure(figsize=(15,15))\n",
        "for i in range(n):\n",
        "    f.add_subplot(1, n, i + 1)\n",
        "    plt.subplot(1, n, i+1 ).axis(\"off\")\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1MuhJxXNM9Q"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxiYagB0QJC"
      },
      "source": [
        "# Creating generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agm_HPniqPI4"
      },
      "source": [
        "gen_model = tf.keras.Sequential()\n",
        "\n",
        "# seed image of size 4x4\n",
        "gen_model.add(tf.keras.layers.Dense(64*4*4, \n",
        "                                use_bias=False, \n",
        "                                input_shape=(100,)))\n",
        "gen_model.add(tf.keras.layers.BatchNormalization())\n",
        "gen_model.add(tf.keras.layers.LeakyReLU())\n",
        "      \n",
        "gen_model.add(tf.keras.layers.Reshape((4,4,64)))\n",
        "\n",
        "# size of output image is still 4x4\n",
        "gen_model.add(tf.keras.layers.Conv2DTranspose(256, (5, 5), \n",
        "                                          strides=(1, 1), \n",
        "                                          padding='same', \n",
        "                                          use_bias=False))\n",
        "gen_model.add(tf.keras.layers.BatchNormalization())\n",
        "gen_model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "# size of output image is 8x8\n",
        "gen_model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), \n",
        "                                          strides=(2, 2), \n",
        "                                          padding='same', \n",
        "                                          use_bias=False))\n",
        "gen_model.add(tf.keras.layers.BatchNormalization())\n",
        "gen_model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "# size of output image is 16x16\n",
        "gen_model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), \n",
        "                                          strides=(2, 2), \n",
        "                                          padding='same', \n",
        "                                          use_bias=False))\n",
        "gen_model.add(tf.keras.layers.BatchNormalization())\n",
        "gen_model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "# size of output image is 32x32\n",
        "gen_model.add(tf.keras.layers.Conv2DTranspose(32, (5, 5), \n",
        "                                          strides=(2, 2), \n",
        "                                          padding='same', \n",
        "                                          use_bias=False))\n",
        "gen_model.add(tf.keras.layers.BatchNormalization())\n",
        "gen_model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "# size of output image is 64x64\n",
        "gen_model.add(tf.keras.layers.Conv2DTranspose(3, (5, 5), \n",
        "                                          strides=(2, 2), \n",
        "                                          padding='same', \n",
        "                                          use_bias=False, \n",
        "                                          activation='tanh'))\n",
        "\n",
        "gen_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyk2C4pA0iM8"
      },
      "source": [
        "# Testing image generator with random input vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QYQ1XBXrhZ7"
      },
      "source": [
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = gen_model(noise, training=False)\n",
        "plt.imshow(generated_image[0, :, :, 0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypqWd3Wh0nk1"
      },
      "source": [
        "# Defining descriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDGxtNOMXGaX"
      },
      "source": [
        "discri_model = tf.keras.Sequential()\n",
        "discri_model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same',input_shape=[64,64,3]))\n",
        "discri_model.add(tf.keras.layers.LeakyReLU())\n",
        "discri_model.add(tf.keras.layers.Dropout(0.3))\n",
        "  \n",
        "discri_model.add(tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
        "discri_model.add(tf.keras.layers.LeakyReLU())\n",
        "discri_model.add(tf.keras.layers.Dropout(0.3))\n",
        "    \n",
        "discri_model.add(tf.keras.layers.Flatten())\n",
        "discri_model.add(tf.keras.layers.Dense(1))\n",
        "discri_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8deuKSO0xS_"
      },
      "source": [
        "tf.keras.utils.plot_model(discri_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwpayBlI04-5"
      },
      "source": [
        "# Testing discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRSZuzJMx1bu"
      },
      "source": [
        "#giving the generated image to discriminator, the discriminator will give negative value if it is fake, while if it is real then it will give positive value.\n",
        "decision = discri_model(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yfav3RL0_iW"
      },
      "source": [
        "# Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMFwv_Yyr1xe"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdShbLLaXNo4"
      },
      "source": [
        "def generator_loss(generated_output):\n",
        "    return cross_entropy(tf.ones_like(generated_output),generated_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcYMh7WxVzj1"
      },
      "source": [
        "def discriminator_loss(real_output, generated_output):\n",
        "    # compute loss considering the image is real [1,1,...,1]\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
        "\n",
        "    # compute loss considering the image is fake[0,0,...,0]\n",
        "    generated_loss = cross_entropy(tf.zeros_like(generated_output),\n",
        "                                   generated_output)\n",
        "    # compute total loss\n",
        "    total_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97SEvznP1GBA"
      },
      "source": [
        "# Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Ar-MVrvVDC"
      },
      "source": [
        "gen_optimizer = tf.optimizers.Adam(1e-4)\n",
        "discri_optimizer = tf.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8_5ZSq81aGT"
      },
      "source": [
        "## Setting up a few variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp5x7WZivYhP"
      },
      "source": [
        "epoch_number = 0\n",
        "EPOCHS = 10000\n",
        "noise_dim = 100\n",
        "seed = tf.random.normal([1, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPeOuE1jsFbY"
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/GAN3/Checkpoint'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optimizer,\n",
        "                                 discriminator_optimizer=discri_optimizer, \n",
        "                                 generator= gen_model,\n",
        "                                 discriminator = discri_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op5eP2ag1oK-"
      },
      "source": [
        "# Mounting drive for storing images and checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t-8QpYJCnIK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W45OxGJcC1hh"
      },
      "source": [
        "cd '/content/drive/My Drive/GAN3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMh-Novp1vio"
      },
      "source": [
        "# Gradient tuning function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQC41IEvvbH9"
      },
      "source": [
        "def gradient_tuning(images):\n",
        "    # create a noise vector.\n",
        "    noise = tf.random.normal([16, noise_dim])\n",
        "\n",
        "    # Use gradient tapes for automatic differentiation \n",
        "    with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape: \n",
        "\n",
        "      # ask genertor to generate random images\n",
        "      generated_images = gen_model(noise, training=True)\n",
        "\n",
        "      # ask discriminator to evalute the real images and generate its output\n",
        "      real_output = discri_model(images, training=True)\n",
        "\n",
        "      # ask discriminator to do the evlaution on generated (fake) images\n",
        "      fake_output = discri_model(generated_images, training=True)\n",
        "\n",
        "      # calculate generator loss on fake data\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "\n",
        "      # calculate discriminator loss as defined earlier\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # calculate gradients for generator\n",
        "    gen_gradients = generator_tape.gradient(gen_loss, \n",
        "                                               gen_model.trainable_variables)\n",
        "\n",
        "    # calculate gradients for discriminator\n",
        "    discri_gradients = discriminator_tape.gradient(disc_loss, \n",
        "                                        discri_model.trainable_variables)\n",
        "\n",
        "    # use optimizer to process and apply gradients to variables\n",
        "    gen_optimizer.apply_gradients(zip(gen_gradients, \n",
        "                                            gen_model.trainable_variables))\n",
        "    \n",
        "    # same as above to discriminator\n",
        "    discri_optimizer.apply_gradients(\n",
        "        zip(discri_gradients, \n",
        "            discri_model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOnc6rSw193B"
      },
      "source": [
        "# Function for generating images at every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5so2rz2OtG"
      },
      "source": [
        "    def generate_and_save_images(model, epoch, test_input):\n",
        "        # use a global count for tracking epochs in case of disconnection\n",
        "        global epoch_number\n",
        "        epoch_number = epoch_number + 1\n",
        "\n",
        "        # set training to false to ensure inference mode\n",
        "        predictions = model(test_input, training=False)\n",
        "\n",
        "        # display and save image\n",
        "        fig = plt.figure(figsize=(4,4))\n",
        "        for i in range(predictions.shape[0]):\n",
        "            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "            plt.axis('off')\n",
        "        plt.savefig('image_at_epoch_{:01d}.png'.format(epoch_number))\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyVb6SqB2hWj"
      },
      "source": [
        "# Setting up a training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMJQeDQx23St"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      gradient_tuning(image_batch)\n",
        "    \n",
        "    # Produce images as we go\n",
        "    generate_and_save_images(gen_model,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "    \n",
        "    # save checkpoint data\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, \n",
        "                                                time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaZSrjIX2qKl"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYqRoZAhp1iM"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aFOcnuC2sBr"
      },
      "source": [
        "### Run following code only if there is a disconnection and you wish to continue training from the last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP3R0plRoRhJ"
      },
      "source": [
        "#run this code only if there is a runtime disconnection\n",
        "try:\n",
        "     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "except Exception as error:\n",
        "    print(\"Error loading in model : {}\".format(error))\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}